{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "I followed along with [this video](https://www.youtube.com/watch?v=fou31n3Win0) for an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a dataset pipeline from numpy or lists\n",
    "\n",
    "Tensorflow dataset is a module used to work with large datasets and to create complex pipelines from simple, reusable pieces. This is typically helpful in cases where a whole dataset does not fit into memory - which is the rule, rather than the exception for many machine learning applications. This is analogous to how file-streams will stream a file line by line, rather than the whole file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor-inception\n",
    "\n",
    "Tensors are a class of objects that, especially in tensorflow, can lead to some confusing nomenclature. This is because abstractly, a tensor is ' is an algebraic object that describes a (multilinear) relationship between sets of algebraic objects related to a vector space. Objects that tensors may map between include vectors and scalars, and even other tensors' ([Wikipedia - Tensor](https://en.wikipedia.org/wiki/Tensor#:~:text=In%20mathematics%2C%20a%20tensor%20is,scalars%2C%20and%20even%20other%20tensors.)). Concretely, this means that the list below `data` is a tensor of rank $1 \\times 3$. So, we create a tensorflow dataset by slicing the `data` tensor along its first axis, therefore, `tf.data.Dataset.from_tensor_slices`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: (), types: tf.int32>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Consider data in memory, and we want to create a dpipeline\n",
    "\n",
    "data = [1, 2, 3, 4] # each piece of data is an example.\n",
    "\n",
    "# Okay - so, here, tensor-inception begins. A tensor is\n",
    "dataset = tf.data.Dataset.from_tensor_slices(data)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did something go wrong? It looks like our data is not there...This is a pointer to our data. We are seeing the representation of the pointer. The shape describes the shape of each example in the dataset - in this case a zero-rank tensor, which is just a scalar (tensor rank 0). We also see the type of each example in the dataset, in this case, tf.int32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Access Data (iteration)\n",
    "\n",
    "for i in dataset:\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay - so now we see more information. In this case, each item in the dataset is a Tensor, with the first argument being a numeric representation of the tensor (its value), with shape () (remember - a scalar), of type int32."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply instructions / transformations\n",
    "\n",
    "Since the dataset is accessed in batches, rather than 'all at once', we have to also define the transformations that are done each time a new batch is accessed in the dataset.\n",
    "\n",
    "Instructions are applies when the dataset is accessed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map\n",
    "\n",
    "Lets say we want to take each element of our data set, and split into two elements - one will be the first element, the second will be the first element multiplied by 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_new_dataset():\n",
    "  dataset = tf.data.Dataset.from_tensor_slices(np.arange(start=1, stop=16, step=1))\n",
    "  dataset = dataset.map(lambda x: (x, x*2))\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(), dtype=int64, numpy=1>, <tf.Tensor: shape=(), dtype=int64, numpy=2>)\n",
      "(<tf.Tensor: shape=(), dtype=int64, numpy=2>, <tf.Tensor: shape=(), dtype=int64, numpy=4>)\n",
      "(<tf.Tensor: shape=(), dtype=int64, numpy=3>, <tf.Tensor: shape=(), dtype=int64, numpy=6>)\n",
      "(<tf.Tensor: shape=(), dtype=int64, numpy=4>, <tf.Tensor: shape=(), dtype=int64, numpy=8>)\n",
      "(<tf.Tensor: shape=(), dtype=int64, numpy=5>, <tf.Tensor: shape=(), dtype=int64, numpy=10>)\n",
      "(<tf.Tensor: shape=(), dtype=int64, numpy=6>, <tf.Tensor: shape=(), dtype=int64, numpy=12>)\n",
      "(<tf.Tensor: shape=(), dtype=int64, numpy=7>, <tf.Tensor: shape=(), dtype=int64, numpy=14>)\n",
      "(<tf.Tensor: shape=(), dtype=int64, numpy=8>, <tf.Tensor: shape=(), dtype=int64, numpy=16>)\n",
      "(<tf.Tensor: shape=(), dtype=int64, numpy=9>, <tf.Tensor: shape=(), dtype=int64, numpy=18>)\n",
      "(<tf.Tensor: shape=(), dtype=int64, numpy=10>, <tf.Tensor: shape=(), dtype=int64, numpy=20>)\n",
      "(<tf.Tensor: shape=(), dtype=int64, numpy=11>, <tf.Tensor: shape=(), dtype=int64, numpy=22>)\n",
      "(<tf.Tensor: shape=(), dtype=int64, numpy=12>, <tf.Tensor: shape=(), dtype=int64, numpy=24>)\n",
      "(<tf.Tensor: shape=(), dtype=int64, numpy=13>, <tf.Tensor: shape=(), dtype=int64, numpy=26>)\n",
      "(<tf.Tensor: shape=(), dtype=int64, numpy=14>, <tf.Tensor: shape=(), dtype=int64, numpy=28>)\n",
      "(<tf.Tensor: shape=(), dtype=int64, numpy=15>, <tf.Tensor: shape=(), dtype=int64, numpy=30>)\n"
     ]
    }
   ],
   "source": [
    "dataset = make_new_dataset()\n",
    "\n",
    "for example in dataset:\n",
    "  print(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See what happened? When we access each element of the dataset, we split it into a tuple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle\n",
    "\n",
    "Shuffle randomizes the order of the dataset. Shuffle will not load the whole dataset into memory - because these datasets can be enormous. So, we have to specify a buffer_size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(5, shape=(), dtype=int64) tf.Tensor(10, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64) tf.Tensor(2, shape=(), dtype=int64)\n",
      "tf.Tensor(3, shape=(), dtype=int64) tf.Tensor(6, shape=(), dtype=int64)\n",
      "tf.Tensor(4, shape=(), dtype=int64) tf.Tensor(8, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64) tf.Tensor(4, shape=(), dtype=int64)\n",
      "tf.Tensor(9, shape=(), dtype=int64) tf.Tensor(18, shape=(), dtype=int64)\n",
      "tf.Tensor(10, shape=(), dtype=int64) tf.Tensor(20, shape=(), dtype=int64)\n",
      "tf.Tensor(11, shape=(), dtype=int64) tf.Tensor(22, shape=(), dtype=int64)\n",
      "tf.Tensor(6, shape=(), dtype=int64) tf.Tensor(12, shape=(), dtype=int64)\n",
      "tf.Tensor(14, shape=(), dtype=int64) tf.Tensor(28, shape=(), dtype=int64)\n",
      "tf.Tensor(12, shape=(), dtype=int64) tf.Tensor(24, shape=(), dtype=int64)\n",
      "tf.Tensor(15, shape=(), dtype=int64) tf.Tensor(30, shape=(), dtype=int64)\n",
      "tf.Tensor(7, shape=(), dtype=int64) tf.Tensor(14, shape=(), dtype=int64)\n",
      "tf.Tensor(8, shape=(), dtype=int64) tf.Tensor(16, shape=(), dtype=int64)\n",
      "tf.Tensor(13, shape=(), dtype=int64) tf.Tensor(26, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "dataset = make_new_dataset()\n",
    "dataset = dataset.shuffle(buffer_size=5)\n",
    "\n",
    "for x, y in dataset:\n",
    "  print(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See? Above, you can see that each set of five examples has been randomized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch\n",
    "\n",
    "Load data in chunks. Each group is loaded separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch # 0\n",
      "\t Batch X:  tf.Tensor([1 2 3], shape=(3,), dtype=int64)\n",
      "\t Batch Y:  tf.Tensor([2 4 6], shape=(3,), dtype=int64)\n",
      "Batch # 1\n",
      "\t Batch X:  tf.Tensor([4 5 6], shape=(3,), dtype=int64)\n",
      "\t Batch Y:  tf.Tensor([ 8 10 12], shape=(3,), dtype=int64)\n",
      "Batch # 2\n",
      "\t Batch X:  tf.Tensor([7 8 9], shape=(3,), dtype=int64)\n",
      "\t Batch Y:  tf.Tensor([14 16 18], shape=(3,), dtype=int64)\n",
      "Batch # 3\n",
      "\t Batch X:  tf.Tensor([10 11 12], shape=(3,), dtype=int64)\n",
      "\t Batch Y:  tf.Tensor([20 22 24], shape=(3,), dtype=int64)\n",
      "Batch # 4\n",
      "\t Batch X:  tf.Tensor([13 14 15], shape=(3,), dtype=int64)\n",
      "\t Batch Y:  tf.Tensor([26 28 30], shape=(3,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "dataset = make_new_dataset()\n",
    "dataset = dataset.batch(batch_size=3)\n",
    "\n",
    "for i, batch in enumerate(dataset):\n",
    "  print(\"Batch #\", i)\n",
    "  batch_x, batch_y = batch\n",
    "  print(\"\\t\", \"Batch X: \", batch_x)\n",
    "  print(\"\\t\", \"Batch Y: \", batch_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look how the data has been reshaped. Rather than storing each example a scaler, now the examples have been batched together in Rank-1 tensors of length 3 (the batch size). This is done (I guess) for efficiency reasons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets From Generators\n",
    "\n",
    "Generators can be used to create tensorflow datasets, but this is inefficient because the generator is not scalable and it is subject to Python's global interpreter lock (GIL) so parallelization across computers is not really possible.\n",
    "\n",
    "Pipeline transformations are **preferred**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "def dataset_generator():\n",
    "  for x in np.arange(start=0, stop=6, step=1):\n",
    "    yield x\n",
    "    \n",
    "dataset = tf.data.Dataset.from_generator(generator=dataset_generator, output_types=tf.int32)\n",
    "\n",
    "for i in dataset:\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FlatMapDataset shapes: <unknown>, types: tf.int32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Tensors\n",
    "\n",
    "When applying transformations on a tf.data.Dataset, we are working with Tensors, not numpy arrays. We might want to do this, for example, when operating on data with categorical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What's the categorical value of 5, considering 10 different ordinal classes?\n",
    "tf.keras.utils.to_categorical(y=5, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works for numeric (integer) embeddings only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1, shape=(), dtype=int64) tf.Tensor(\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], shape=(30,), dtype=float32)\n",
      "tf.Tensor(2, shape=(), dtype=int64) tf.Tensor(\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], shape=(30,), dtype=float32)\n",
      "tf.Tensor(3, shape=(), dtype=int64) tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], shape=(30,), dtype=float32)\n",
      "tf.Tensor(4, shape=(), dtype=int64) tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], shape=(30,), dtype=float32)\n",
      "tf.Tensor(5, shape=(), dtype=int64) tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], shape=(30,), dtype=float32)\n",
      "tf.Tensor(6, shape=(), dtype=int64) tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], shape=(30,), dtype=float32)\n",
      "tf.Tensor(7, shape=(), dtype=int64) tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], shape=(30,), dtype=float32)\n",
      "tf.Tensor(8, shape=(), dtype=int64) tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], shape=(30,), dtype=float32)\n",
      "tf.Tensor(9, shape=(), dtype=int64) tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], shape=(30,), dtype=float32)\n",
      "tf.Tensor(10, shape=(), dtype=int64) tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], shape=(30,), dtype=float32)\n",
      "tf.Tensor(11, shape=(), dtype=int64) tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0.], shape=(30,), dtype=float32)\n",
      "tf.Tensor(12, shape=(), dtype=int64) tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0.], shape=(30,), dtype=float32)\n",
      "tf.Tensor(13, shape=(), dtype=int64) tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0.], shape=(30,), dtype=float32)\n",
      "tf.Tensor(14, shape=(), dtype=int64) tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0.], shape=(30,), dtype=float32)\n",
      "tf.Tensor(15, shape=(), dtype=int64) tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], shape=(30,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def cat_encode(x, y):\n",
    "  return x, tf.one_hot(y, 30)\n",
    "\n",
    "dataset = make_new_dataset()\n",
    "dataset = dataset.map(cat_encode)\n",
    "\n",
    "for example in dataset:\n",
    "  x, y = example\n",
    "  print(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with Dataset API\n",
    "\n",
    "Just pass to .fit!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
